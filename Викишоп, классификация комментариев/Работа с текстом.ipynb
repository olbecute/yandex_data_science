{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Общее-впечатление\" data-toc-modified-id=\"Общее-впечатление-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление</font></a></span></li><li><span><a href=\"#Общее-впечатление-(ревью-2)\" data-toc-modified-id=\"Общее-впечатление-(ревью-2)-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление (ревью 2)</font></a></span></li></ul></li><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем нужные библиотеки \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузим библиотеку для работы с текстом, а также набот \"стоп-слоб\" и теггер\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords') \n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для общей информации\n",
    "\n",
    "def data_info(df):\n",
    "    print('Первые 10 записей')\n",
    "    display(df.head(10))\n",
    "    print()\n",
    "    print('-' * 70)\n",
    "    print()\n",
    "    print(\"Обащая информация\")\n",
    "    display(df.info())\n",
    "    print()\n",
    "    print('-' * 70)\n",
    "    print()\n",
    "    display(df.describe().T)\n",
    "    print()\n",
    "    print('-' * 70)\n",
    "    print()\n",
    "    print('Количество дубликатов')\n",
    "    display(df.duplicated().unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/toxic_comments.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Первые 10 записей\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0\n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7  Your vandalism to the Matt Shirvington article...      0\n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9  alignment on this subject and which are contra...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Обащая информация\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <td>159292.0</td>\n",
       "      <td>0.101612</td>\n",
       "      <td>0.302139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count      mean       std  min  25%  50%  75%  max\n",
       "toxic  159292.0  0.101612  0.302139  0.0  0.0  0.0  0.0  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Количество дубликатов\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_info(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Тональность комментариев'}, ylabel='Тональность'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Построим круглую диаграмму, чтобы посмотреть соотношение позитивных и негативных отзывов\n",
    "\n",
    "df['toxic'].value_counts().plot(y = 'count', \n",
    "                                kind = 'pie', \n",
    "                                autopct='%1.0f%%', \n",
    "                                title = 'Тональность комментариев', \n",
    "                                legend = True, \n",
    "                                ylabel = 'Тональность')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция обработки текста, теггирования\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Лемматизация текста\n",
    "\n",
    "def lemmatize(text):\n",
    "    m = WordNetLemmatizer()\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\']', ' ', text)\n",
    "    text = text.split()\n",
    "    return ' '.join([m.lemmatize(i, get_wordnet_pos(i)) for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2271edcc66d4d4aa6bd202af5f06023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df['new_text'] = df['text'].progress_apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>new_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits make under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww he match this background colour i'm seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i'm really not try to edit war it's ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can't make any real suggestion on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>congratulation from me a well use the tool wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>cocksucker before you piss around on my work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>your vandalism to the matt shirvington article...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>sorry if the word 'nonsense' be offensive to y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>alignment on this subject and which be contrar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0   \n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
       "7  Your vandalism to the Matt Shirvington article...      0   \n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0   \n",
       "9  alignment on this subject and which are contra...      0   \n",
       "\n",
       "                                            new_text  \n",
       "0  explanation why the edits make under my userna...  \n",
       "1  d'aww he match this background colour i'm seem...  \n",
       "2  hey man i'm really not try to edit war it's ju...  \n",
       "3  more i can't make any real suggestion on impro...  \n",
       "4  you sir be my hero any chance you remember wha...  \n",
       "5  congratulation from me a well use the tool wel...  \n",
       "6       cocksucker before you piss around on my work  \n",
       "7  your vandalism to the matt shirvington article...  \n",
       "8  sorry if the word 'nonsense' be offensive to y...  \n",
       "9  alignment on this subject and which be contrar...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим результат\n",
    "\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "\n",
    "* Пропусков в данных нет;\n",
    "* Типы данных заданы корректно;\n",
    "* Отрицательных отзывов в разы меньше чем положительных в соотношении 1 к 9;\n",
    "* Также былаа проведена лемматизация текста и очистка от регулярных выражений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделим данные\n",
    "\n",
    "y = df['toxic']\n",
    "X = df.drop(['toxic'], axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, \n",
    "        y, \n",
    "        random_state=RANDOM_STATE\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим set, множество, со \"стоп-словами\" на английском языке\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем текст в матрицу TF-IDF на тренировочной выборке\n",
    "\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stop_words)\n",
    "tf_idf = count_tf_idf.fit_transform(X_train['new_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование текста тестовой выборки\n",
    "\n",
    "test_tf_idf = count_tf_idf.transform(X_test['new_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 78033)\t0.3308752594213566\n",
      "  (0, 65520)\t0.4039259522331161\n",
      "  (0, 91535)\t0.49971500455089807\n",
      "  (0, 106197)\t0.2347524695870796\n",
      "  (0, 3721)\t0.2575271947578143\n",
      "  (0, 92373)\t0.23357611435456094\n",
      "  (0, 659)\t0.34989557616378414\n",
      "  (0, 3740)\t0.3753752686171005\n",
      "  (0, 104705)\t0.1957805310027853\n",
      "  (1, 107929)\t0.23463353601129977\n",
      "  (1, 112311)\t0.134682141492955\n",
      "  (1, 51739)\t0.28289377866399285\n",
      "  (1, 50639)\t0.4099793126146299\n",
      "  (1, 45445)\t0.1542531717966754\n",
      "  (1, 50625)\t0.2528732598888444\n",
      "  (1, 40077)\t0.16285597081660455\n",
      "  (1, 112980)\t0.1405634726697469\n",
      "  (1, 90196)\t0.17550545234525408\n",
      "  (1, 69331)\t0.20390021912317077\n",
      "  (1, 64669)\t0.19826480539592867\n",
      "  (1, 104351)\t0.17447295881989822\n",
      "  (1, 76168)\t0.1455557317549952\n",
      "  (1, 71423)\t0.17943110225281822\n",
      "  (1, 33819)\t0.16512785004440234\n",
      "  (1, 94575)\t0.23945099799835962\n",
      "  :\t:\n",
      "  (119468, 98008)\t0.12639170413820486\n",
      "  (119468, 93672)\t0.22453368761150655\n",
      "  (119468, 21940)\t0.11417083100525657\n",
      "  (119468, 122525)\t0.11628219209009805\n",
      "  (119468, 54922)\t0.11473757605522186\n",
      "  (119468, 125464)\t0.10767912616456517\n",
      "  (119468, 47119)\t0.2374245294259941\n",
      "  (119468, 95007)\t0.14685947627923893\n",
      "  (119468, 78312)\t0.2385735465493787\n",
      "  (119468, 84720)\t0.10330681787272256\n",
      "  (119468, 78307)\t0.256668316786897\n",
      "  (119468, 23251)\t0.09900818136963596\n",
      "  (119468, 80370)\t0.07047848801929871\n",
      "  (119468, 65003)\t0.09015261337139535\n",
      "  (119468, 104591)\t0.11015406586262591\n",
      "  (119468, 107494)\t0.10941469607249035\n",
      "  (119468, 125413)\t0.09078798670139533\n",
      "  (119468, 98644)\t0.07529857179634557\n",
      "  (119468, 67525)\t0.07001625480527396\n",
      "  (119468, 107924)\t0.11178901350965564\n",
      "  (119468, 109979)\t0.06381322798220532\n",
      "  (119468, 118788)\t0.07341908922833065\n",
      "  (119468, 7003)\t0.05756032631822694\n",
      "  (119468, 3740)\t0.07727541016653154\n",
      "  (119468, 104705)\t0.32242978375421644\n"
     ]
    }
   ],
   "source": [
    "print(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем паплайны\n",
    "\n",
    "pipe_final= Pipeline([\n",
    "    ('models', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = [\n",
    "    {\n",
    "        'models': [LogisticRegression()],\n",
    "        'models__penalty': ['l2'],\n",
    "        'models__C': [0.1, 1, 10, 100]\n",
    "    },\n",
    "    {\n",
    "        'models': [LogisticRegression()],\n",
    "        'models__penalty': ['none']\n",
    "    },\n",
    "    {\n",
    "        'models': [CatBoostClassifier(random_state = RANDOM_STATE)],\n",
    "        'models__iterations': [range(100, 601, 100)]\n",
    "    }\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/catboost/core.py\", line 4716, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/catboost/core.py\", line 2021, in _fit\n",
      "    train_params = self._prepare_train_params(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/catboost/core.py\", line 1953, in _prepare_train_params\n",
      "    _check_train_params(params)\n",
      "  File \"_catboost.pyx\", line 5839, in _catboost._check_train_params\n",
      "  File \"_catboost.pyx\", line 5857, in _catboost._check_train_params\n",
      "  File \"_catboost.pyx\", line 1712, in _catboost._PreprocessParams.__init__\n",
      "  File \"/opt/conda/lib/python3.9/json/__init__.py\", line 234, in dumps\n",
      "    return cls(\n",
      "  File \"/opt/conda/lib/python3.9/json/encoder.py\", line 199, in encode\n",
      "    chunks = self.iterencode(o, _one_shot=True)\n",
      "  File \"/opt/conda/lib/python3.9/json/encoder.py\", line 257, in iterencode\n",
      "    return _iterencode(o, 0)\n",
      "  File \"_catboost.pyx\", line 144, in _catboost._NumpyAwareEncoder.default\n",
      "  File \"/opt/conda/lib/python3.9/json/encoder.py\", line 179, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type range is not JSON serializable\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/catboost/core.py\", line 4716, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/catboost/core.py\", line 2021, in _fit\n",
      "    train_params = self._prepare_train_params(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/catboost/core.py\", line 1953, in _prepare_train_params\n",
      "    _check_train_params(params)\n",
      "  File \"_catboost.pyx\", line 5839, in _catboost._check_train_params\n",
      "  File \"_catboost.pyx\", line 5857, in _catboost._check_train_params\n",
      "  File \"_catboost.pyx\", line 1712, in _catboost._PreprocessParams.__init__\n",
      "  File \"/opt/conda/lib/python3.9/json/__init__.py\", line 234, in dumps\n",
      "    return cls(\n",
      "  File \"/opt/conda/lib/python3.9/json/encoder.py\", line 199, in encode\n",
      "    chunks = self.iterencode(o, _one_shot=True)\n",
      "  File \"/opt/conda/lib/python3.9/json/encoder.py\", line 257, in iterencode\n",
      "    return _iterencode(o, 0)\n",
      "  File \"_catboost.pyx\", line 144, in _catboost._NumpyAwareEncoder.default\n",
      "  File \"/opt/conda/lib/python3.9/json/encoder.py\", line 179, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type range is not JSON serializable\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/catboost/core.py\", line 4716, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/catboost/core.py\", line 2021, in _fit\n",
      "    train_params = self._prepare_train_params(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/catboost/core.py\", line 1953, in _prepare_train_params\n",
      "    _check_train_params(params)\n",
      "  File \"_catboost.pyx\", line 5839, in _catboost._check_train_params\n",
      "  File \"_catboost.pyx\", line 5857, in _catboost._check_train_params\n",
      "  File \"_catboost.pyx\", line 1712, in _catboost._PreprocessParams.__init__\n",
      "  File \"/opt/conda/lib/python3.9/json/__init__.py\", line 234, in dumps\n",
      "    return cls(\n",
      "  File \"/opt/conda/lib/python3.9/json/encoder.py\", line 199, in encode\n",
      "    chunks = self.iterencode(o, _one_shot=True)\n",
      "  File \"/opt/conda/lib/python3.9/json/encoder.py\", line 257, in iterencode\n",
      "    return _iterencode(o, 0)\n",
      "  File \"_catboost.pyx\", line 144, in _catboost._NumpyAwareEncoder.default\n",
      "  File \"/opt/conda/lib/python3.9/json/encoder.py\", line 179, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type range is not JSON serializable\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/catboost/core.py\", line 4716, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/catboost/core.py\", line 2021, in _fit\n",
      "    train_params = self._prepare_train_params(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/catboost/core.py\", line 1953, in _prepare_train_params\n",
      "    _check_train_params(params)\n",
      "  File \"_catboost.pyx\", line 5839, in _catboost._check_train_params\n",
      "  File \"_catboost.pyx\", line 5857, in _catboost._check_train_params\n",
      "  File \"_catboost.pyx\", line 1712, in _catboost._PreprocessParams.__init__\n",
      "  File \"/opt/conda/lib/python3.9/json/__init__.py\", line 234, in dumps\n",
      "    return cls(\n",
      "  File \"/opt/conda/lib/python3.9/json/encoder.py\", line 199, in encode\n",
      "    chunks = self.iterencode(o, _one_shot=True)\n",
      "  File \"/opt/conda/lib/python3.9/json/encoder.py\", line 257, in iterencode\n",
      "    return _iterencode(o, 0)\n",
      "  File \"_catboost.pyx\", line 144, in _catboost._NumpyAwareEncoder.default\n",
      "  File \"/opt/conda/lib/python3.9/json/encoder.py\", line 179, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type range is not JSON serializable\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/catboost/core.py\", line 4716, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/catboost/core.py\", line 2021, in _fit\n",
      "    train_params = self._prepare_train_params(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/catboost/core.py\", line 1953, in _prepare_train_params\n",
      "    _check_train_params(params)\n",
      "  File \"_catboost.pyx\", line 5839, in _catboost._check_train_params\n",
      "  File \"_catboost.pyx\", line 5857, in _catboost._check_train_params\n",
      "  File \"_catboost.pyx\", line 1712, in _catboost._PreprocessParams.__init__\n",
      "  File \"/opt/conda/lib/python3.9/json/__init__.py\", line 234, in dumps\n",
      "    return cls(\n",
      "  File \"/opt/conda/lib/python3.9/json/encoder.py\", line 199, in encode\n",
      "    chunks = self.iterencode(o, _one_shot=True)\n",
      "  File \"/opt/conda/lib/python3.9/json/encoder.py\", line 257, in iterencode\n",
      "    return _iterencode(o, 0)\n",
      "  File \"_catboost.pyx\", line 144, in _catboost._NumpyAwareEncoder.default\n",
      "  File \"/opt/conda/lib/python3.9/json/encoder.py\", line 179, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type range is not JSON serializable\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.47484651 0.7137048  0.76128987 0.75414979 0.7278353         nan]\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Pipeline(steps=[('models', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'models': [LogisticRegression(C=10)],\n",
       "                          'models__C': [0.1, 1, 10, 100],\n",
       "                          'models__penalty': ['l2']},\n",
       "                         {'models': [LogisticRegression()],\n",
       "                          'models__penalty': ['none']},\n",
       "                         {'models': [<catboost.core.CatBoostClassifier object at 0x7ffadc8185b0>],\n",
       "                          'models__iterations': [range(100, 601, 100)]}],\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = GridSearchCV(\n",
    "    pipe_final, \n",
    "    param_distributions, \n",
    "    cv = 5,\n",
    "    scoring='f1', \n",
    "    n_jobs=-1\n",
    ")\n",
    "search.fit(tf_idf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказание\n",
    "\n",
    "new_predict = search.predict(test_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение метрики f1 =  0.773\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_test, new_predict)\n",
    "\n",
    "print('Значение метрики f1 = ', round(f1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель:  Pipeline(steps=[('models', LogisticRegression(C=10))])\n"
     ]
    }
   ],
   "source": [
    "print('Лучшая модель: ', search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе выполнения проекта была проведена комплексная работа по анализу текстов комментариев и их классификации на позитивные и негативные отзывы. Загрузка датафрейма завершилась успешно, при этом обнаружено, что данные не содержат пропусков, а типы данных заданы корректно. В результате анализа распределения меток классов установлено, что 90% комментариев являются позитивными, что подчеркивает переизбыток положительных отзывов в выборке.\n",
    "\n",
    "Для подготовки текстовых данных к моделированию выполнены следующие шаги: \n",
    "* лемматизация текста \n",
    "* очистка от шумов с помощью регулярных выражений. \n",
    "Это позволило улучшить качество входных данных и повысить точность предсказаний.\n",
    "\n",
    "Данные были разделены на тренировочный и тестовый наборы, после чего текст был преобразован в TF-IDF матрицу, что является стандартной практикой для векторизации текстов. Дополнительно, был создан пайплайн, который обеспечил интеграцию всех этапов подготовки данных и обучения моделей.\n",
    "\n",
    "Результаты обучения моделей логистической регрессии и CatBoost продемонстрировали высокую эффективность, при этом метрика F1 составила **0.773**, что превышает заданный порог в 0.75. Лучшая модель, полученная в процессе, это **LogisticRegression с параметром C=10**. \n",
    "\n",
    "Данный проект демонстрирует успешное применение методов обработки естественного языка и машинного обучения для анализа тональности комментариев. Результаты модели показывают её способность адекватно классифицировать отзывы, что может быть полезно для различных приложений в области анализа потребительских мнений и автоматизации обработки отзывов. В дальнейшем стоит рассмотреть возможность применения других алгоритмов и методов для улучшения качества предсказаний и анализа влияния различных параметров на результаты модели."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1400,
    "start_time": "2024-12-15T10:46:12.966Z"
   },
   {
    "duration": 698,
    "start_time": "2024-12-15T10:48:45.422Z"
   },
   {
    "duration": 12,
    "start_time": "2024-12-15T10:49:27.816Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-15T10:50:15.255Z"
   },
   {
    "duration": 1278,
    "start_time": "2024-12-15T10:50:30.605Z"
   },
   {
    "duration": 178,
    "start_time": "2024-12-15T10:50:39.806Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-15T10:50:45.446Z"
   },
   {
    "duration": 53,
    "start_time": "2024-12-15T10:50:47.671Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-15T10:51:20.526Z"
   },
   {
    "duration": 45,
    "start_time": "2024-12-15T10:51:22.422Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-15T10:51:33.191Z"
   },
   {
    "duration": 72,
    "start_time": "2024-12-15T10:51:35.911Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-15T10:52:11.217Z"
   },
   {
    "duration": 297,
    "start_time": "2024-12-15T10:52:14.174Z"
   },
   {
    "duration": 673,
    "start_time": "2024-12-15T10:53:15.480Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-15T10:56:39.992Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-15T10:56:52.153Z"
   },
   {
    "duration": 1146873,
    "start_time": "2024-12-15T10:57:00.086Z"
   },
   {
    "duration": 9,
    "start_time": "2024-12-15T11:16:20.186Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-15T11:22:31.819Z"
   },
   {
    "duration": 57,
    "start_time": "2024-12-15T11:22:42.427Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-15T11:24:21.060Z"
   },
   {
    "duration": 5482,
    "start_time": "2024-12-15T11:25:32.220Z"
   },
   {
    "duration": 8,
    "start_time": "2024-12-15T11:25:59.659Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-15T11:26:22.451Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-15T11:26:26.315Z"
   },
   {
    "duration": 33,
    "start_time": "2024-12-15T11:26:39.244Z"
   },
   {
    "duration": 1658,
    "start_time": "2024-12-15T11:27:20.012Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-15T11:27:42.917Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-15T11:27:54.651Z"
   },
   {
    "duration": 45,
    "start_time": "2024-12-15T11:28:01.996Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-15T11:31:04.229Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-15T11:31:13.349Z"
   },
   {
    "duration": 958553,
    "start_time": "2024-12-15T11:31:20.020Z"
   },
   {
    "duration": 95,
    "start_time": "2024-12-15T11:47:18.576Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-15T11:47:18.672Z"
   },
   {
    "duration": 115,
    "start_time": "2024-12-15T11:47:18.690Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
